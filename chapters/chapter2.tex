\chapter{Related Work\label{cha:chapter2}}
The focus of this thesis lies on the practice of utilizing motion information in order to reconstruct user interactions. As this practice is a form of eavesdropping, this chapter will shed light into similar approaches of side-channel attacks that have been revealed by researchers in the past. The first section deals with different device emanations that have been utilized in various forms to obtain confidential information. The second section covers the foundations of this work as it discusses previous similar attempts predict tap locations on smartphone screens.

\section{Eavesdropping on Emanations}

Eavesdropping is defined as the the practice of secretly listening to private conversations of others without their consent \cite{black1990black}. As this definition originally refers to conversations between humans, eavesdropping can also be seen in terms of human-computer-interaction. In this context, the computer is seen as one conversational partner whereas the user interacting with the device is seen as the other. As the channel of communication in a human conversation is the acoustic channel, the channel in which human-computer interaction takes place has various forms. Typically, a human may enter information on a peripheral device while the computer gives feedback through an image representation. However, speech interfaces and other forms of interaction are also possible. In order to spy on the human-computer conversation, a third party with malicious intent must apply different techniques in order to spy on these interactions. A subset of these techniques which involve the utilization of device emanations will be discussed in this chapter.\\

In this context, a frequently discussed practice throughout academia involves the use of leaking emanations for eavesdropping purposes. These emanations can be monitored in order to carefully reconstruct the contained information. As these emanations occur in various formats, a categorization has been done based on the sensory channel they transpire. Therefore, the following sections will cover eavesdropping techniques based on acoustic, optical, electromagnetic and motion emanations.

% Eavesdropping is secretly listening to the private conversation of others without their consent, as defined by Black's Law Dictionary.[1]
% two words in interaction and 
% Inferring user interactions through side channels has been of great interest to the academic world throughout history. As this thesis will cover a modern approach by recording sensory information provided by the Apple iPhone, an early and prominent example of spying on emanations reaches far back in time. \\

%   % not having to modify the host system.

% Ever since, various user interaction inference experiments have been conducted by researchers worldwide. However, in order to categorize these different approaches found in literature, we will divide these based on the emanation channel that was spied on. This categorization approach is more suitable since device model and user interaction strategies have frequently changed in time.\\ 

% The literature denoted that user inference can be perused with the help of acoustic, optical, electro-magnetic and on sensory emanation. We will describe these in the following sections.

\subsection{Acoustic Emanations}
One way of spying on electrical devices is by utilizing the acoustic channel \cite{Backes:2010:ASA:1929820.1929847,1301311,Zhuang:2009:KAE:1609956.1609959}. Many electronic devices deploy tiny mechanics that generate sounds as a byproduct during interactions or during operation. These distinct sounds can differ in their characteristics making them adequate to identify the original information currently being processed by the machine. In these scenarios an eavesdropper targets a microphone in near proximity of the target device to capture the audio signals the device is exposing. A learning algorithm is then applied to the audio signals to reconstruct information. \\

In 2010, \citeauthor{Backes:2010:ASA:1929820.1929847} examined the problem of acoustic emanations of dot matrix printers, which where, at that time, still commonly used in banks and medical offices. By using a simple consumer-grade microphone, the researchers were able to recover whole sentences the printer was printing based. \citeauthor{Backes:2010:ASA:1929820.1929847} processed the audio samples in order to extracted frequency-domain features. These features worked as input for a hidden markov model, a technology commonly used in audio speech recognition. As a result, the recognition system was able to reconstruct individual characters based on the sound inputs. To demonstrate a potential attack, the researchers deployed the system in a medical office being able to obtain up to 72\% of the sentences being printed on medical subscriptions \cite{Backes:2010:ASA:1929820.1929847}. \\

Being inspired by the findings concerning the dot matrix printer, \citeauthor{1301311} investigated acoustic emanations produced by hitting keystrokes on a desktop and a notebook keyboard. Following their hypothesis claiming that each keystroke has a macroscopic difference in it's construction mechanics, as well as a distinct reverberation caused by the position in the board, individual keystrokes were recorded \cite{1301311}. Researchers then extracted frequency domain features from the audio signals and passed them into a neural network. In an experiment performing 300 keystrokes, 79\% of the characters could be correctly recognized \cite{1301311}. As this technique required substantial training before recognition, other studies have reached similar accuracies using an unsupervised approach \cite{Zhuang:2009:KAE:1609956.1609959} on the one hand and by using acoustic dictionaries \cite{Berger:2006:DAU:1180405.1180436} on the other.

% Maybe some text to round things up...
\subsection{Optical Emanation}
Besides acoustic emanations, optical emanations can also pose a valuable source of information for a potential eavesdropper. Most electronic devices, such as notebook, smartphones and tablet computers, provide graphical user interfaces through their own built-in screens. Even though these screens are meant to target the human eye, they can reflect off other surfaces. The reflections can be caught by high resolution camera sensors, which can then display the image revealing secret information.\\

One example of the use of optical emanations has been developed by \citeauthor{1004358} aiming to eavesdrop on cathode-ray-tube(CRT) monitors at distance. The researcher has shown that the information displayed on the monitor can be reconstructed from its distorted or even diffusely reflected light. In an experiment, \citeauthor{1004358} targeted a screen displaying an image against a wall while the reflections of the screen were captured using a photomultiplier. The experiment showed that enough high-frequency content remained in the emitted light for a computer to reconstruct the original image \cite{1004358}. A similar approach that comprises reflections has been shown by \citeauthor{4531151}, however focusing on LCD displays. In this experiment, the researchers caught reflections in various objects that are commonly to be found in close proximity to a computer screen. Such objects included eyeglasses, tea pots, spoons and even plastic bottles. This work was later extended to additionally capture screens based on the reflections on the human eye's cornea \cite{5207653}.

\subsection{Electro-magnetic Emanation}

As electric currents flow through computer components, they emit electromagnetic waves to their near surrounding. These electromagnetic radiations can be picked up as a side channel using sensitive equipment in order to retrieve data. Electromagnetic emanations have been a research topic that has been present for several decades while the first research conducted reaches far in time. \\

Back in 1943, a research group under the codename TEMPEST, a subdivision of the NSA\footnote{National Security Agency}, were able to infer information from the infamous Bell Telephone model 131-B2, a teletype terminal which was used for encrypting wartime communication \cite{tempest}. Using an oscilloscope, researchers could capture leaking electromagnetic signals from the device and by carefully examining the peaks of the recorded signals, the plain message the device was currently processing could be reconstructed \cite{tempest}. This technique was later advanced and used in the the Vietnam war. Through similar electric emanation the US military could detect approaching Viet Cong trucks giving them an immense competitive advantage \cite{nalty2005war}. Today, TEMPEST is a security standard for electronic devices ensuring that certified devices do not accidently emanate confidential information \cite{niaTempest}.\\

A second prominent finding of eavesdropping on electromagnetic emanations was done by the researcher \citeauthor{vanEck:1985:ERV:7307.7308}, who discovered that cathode-ray-tube monitors could be spied upon from a distance \cite{vanEck:1985:ERV:7307.7308}. By using general market equipment, such as antennas \citeauthor{vanEck:1985:ERV:7307.7308} and standard receivers, signals emitted from the cable connecting the computer to the monitor could be received. Since these cables only transmit the video signal for visualization, the researcher could display the visual output of the target monitor revealing a full screen cast of the original image. This attack is referred to in literature as \textit{Van Eck Phreaking} \cite{S&S,koch2012role}.\\

Furthermore, research has shown that side-band electromagnetic emanations are present in keyboards \cite{Vuagnoux:2009:CEE:1855768.1855769}, computer screens \cite{vanEck:1985:ERV:7307.7308,kuhn2004electromagnetic}, printers \cite{przesmycki2014measurement}, computer interfaces, such as USB 2 \cite{nowosielski2014compromising} and the parallel port \cite{serialcablearticle} and in Smart Cardes\cite{Quisquater:2001:EAM:646803.705980}.\\

\subsection{Motion Emanation}
In the past decade modern devices are increasingly equipeed with highly responsive sensors, such as the gyroscope and accelerometer enabling the devices to sense rich interactions with their environment. As user interactions, such as typing the keyboard or tapping on touchscreens, require the user to apply a certain force while entering information, this motion can be captured by motion sensors in order to be used for a side-channel attack \cite{Tapprints,Accessory,Touchlogger}. \\

\citeauthor{Marquardt:2011:IDV:2046707.2046771} conducted an experiment where an Apple iPhone that captures accelerometer motion was placed next to a dekstop keyboard. Subjects then had to enter sentences while the application was monitoring the user's motion. The researchers could decode the accelerometer signals by mapping the certain vibration caused the typing motion to their keystrokes. The decoded characters were then matched based on a dictionary containing a frequency distribution of commonly used words. As a result, words could be successfully obtained with an accuracy of up to 80\% \cite{Marquardt:2011:IDV:2046707.2046771}.\\

As motion emanations are highly relevant for the work in this thesis, the next section will be dedicated to further work regarding this topic.

\section{Eavesdropping on touch screen user interactions}
As we have seen in the previous section, user interactions with peripheral devices, such as the keyboard or PIN pads, can be obtained by either the acoustic channel, by electromagnetical leakage or by capturing the motion of the user. However, with the rise in soft keyboard usage, the same discussed methods that extract information from keyboard do not apply to tap interactions on a touchscreen surface. Since a touchscreen does not embody fine mechanics producing sounds nor does it have emanating cables, the research community has developed nouvelle methods to spy on user inputs based on the smartphone embodied motion sensors.\\

The general idea behind the three approaches that are going to be discuss in the following is that a tap, or to be more precise the magnitude of the force of a tap, on a specific touch screen location creates an identifiable pattern on the motion sensors that can be sufficient to infer the initial tap location. This is particularly interesting since motion sensors are not considered as being privacy-sensitive and therefore lack access restrictions by the operating systems of the devices.

\subsubsection{Touchlogger}

The first paper regarding this security threat was published by \citeauthor{Touchlogger}. In their proof-of-concept study they created an Android\footnote{Android operating system for smartphones by Google Inc.} application which displays a 10-digit PIN-pad. During interactions with the PIN-pad, the accelerometer signals were monitored and used for later data analysis. Having observed that a tap movement affects the rotation angle of the screen, the researchers handcrafted features based on the path of the \textit{pitch}\footnote{The pitch-angle corresponds to the x-axis of the accelerometer.} and the \textit{roll}\footnote{The roll angle corresponds to the y-axis of the accelerometer.} angles of the accelerometer. These were intersected to find a dominating edge on where the tap had presumably taken place. By using a probability density function for a Gaussian distribution the researchers were able to achieve an average accuracy of 70\% for interred PIN-pad digits. The training set size involved 449 pin strokes \cite{Touchlogger}. Even though\textit{Touchlogger} was a promising first step, due to it's low granularity of only 10 distinguishable large screen areas, it remained unclear if the attack can be carried over to a full software keyboard. Furthermore, since the inference was performed on only a single smartphone model, the question is left open whether other smartphones or tablet computers are similarly vulnerable.

\subsubsection{ACCessory}

In order to show the feasibility for a full software keyboard, \citeauthor{Accessory} performed a second attempt to the problem by creating \textit{ACCessory}. \textit{ACCessory} is an Android application with functionalities similar to the previously mentioned \textit{Touchlogger}. However, the application significantly differ in it's tap area granularity providing two separate modes for tap inputs: \textit{area mode} and \textit{character mode}. \textit{area mode} consists of tap areas arranged in a 60-cell grid, whereas a QWERTY keyboard within landscape orientation was displayed in \textit{character mode}. Having extracted features mainly from the time-domain, a classification using the Random Forests algorithm reached an accuracy of 24.5\% for the 60-cell grid. Here, the corresponding dataset consisted of 1300 keystrokes collected from 4 participants. As the \textit{area mode} experiment focused on recognizing individual keystrokes, the \textit{character mode} experiment focused on cracking passwords. By combining the keystrokes into a sequence and assuming recognition errors in individual characters, the researchers could create a ranked list of candidate passwords by running a maximum likelihood search for the most probable classification errors for an obtained password. Here, 6 out of 99 password could be inferred under 4.5 median trials given that one trails refers to traversing down one item of the candidate list. Furthermore, the majority of 59 out of 99 passwords could be inferred within $2^{15}$ median trials. As general result, even though the overall accuracy of the learning system scored low, the researchers could significantly reduce the search space for reconstructing a password indicating that accelerometer readings can in deed yield confidential information.

\subsubsection{TapPrints}

The most comprehensive study to date regarding the topic was conducted by \citeauthor{Tapprints} and differs from \textit{ACCessory} and \textit{Touchlogger} in many important ways. While both previous studies are both evaluated on the Android smartphones, \textit{TapPrints} investigates the tap inference on both iOS and Android operating systems including tablets and smartphones alike. Another important point of differentiation is the used learning system. In order to raise the level of entropy, \textit{TapPrints} combines readings from the accelerometer and gyroscope for a more sophisticated feature extraction. Here, time-domain and frequency-domain features, as well as the correlation and angles between individual sensor components are considered. For classification purposes, the researchers use an ensemble method combining decision tress, support vector machines, k-nearest neighbors and multinomial logistic regression in a winner-takes-it-all\footnote{This implies that all classifiers classify separately and the classifier with the highest prediction score wins.} voting fashion. The dataset collected in this experiments contains over 40.000 individual taps collected from 10 different users. In addition, the researchers also requested user to use different input modalities while typing including the usage of the index finger and thumb.\\

The \textit{TapPrints} undertaking consists of two separate experiments: The first is a icon tapping experiment where icons are arranged in a 20 cell grid and the second one being a letter tapping experiment involving the standard software keyboard offered by the operating system. In the first experiment, an average accuracy of 78\% was achieved for the iPhone whereas 67\% of icon taps could be correctly inferred on the Android device.
In the letter tapping experiment users were asked to enter pangram\footnote{A pangram is a sentence using every letter of a given alphabet at least once.} sentences on the OS soft-keyboard. Results showed that on both iPhone and Android an average of 43\% of the letters could be correctly classified. Even though the average accuracy for individual letters were not particularly high, \citeauthor{Tapprints} could show that when pangrams were repeatedly entered, a majority vote could be applies to individual character recognitions allowing to recover the whole pangram in approx. 15 trials. To conclude, \textit{TapPrints} could demonstrate that motion sensor can be used to obtain passwords on multiple platforms and formats and with different input modalities.

\subsubsection{Comparison to similar studies}

Since the data used in \textit{TapPrints} and in the other related work was collected in a controlled environment \cite{Accessory,Touchlogger,Tapprints}, it is not possible to tell if the feasibility of tap inference will also apply to data collected in a field environment. As this has not been investigated, this will form the central research question in this thesis. Additional questions will be discussed in the hypothesis section.\\ % TODO: reference\\

To draw the border between this study and the previous mentioned ones, this study will differ or relate as follows:
% TODO: build reference to individual chapters
\begin{itemize}
  \item \textbf{User interface}: For data acquisition, the user interface will cover tap area grids, as we have seen in \textit{ACCessory} and \textit{Touchlogger}, with 4, 12 and 20 distinguishable classes.
  \item \textbf{Devices}: Unlike \textit{Touchlogger} and \textit{ACCessory}, the devices used for this study are on the iOS Platform. Apple iPhone 6, 6s and 7 will be considered due to their mutual screen size.
  \item \textbf{Motion sensors}: \textit{TapPrints} has shown that the gyroscope yields more information than the accelerometer \cite{Tapprints}, therefore both sensors will be monitored. Furthermore, sensors will be read at a frequency of 100Hz, since this had been proven to deliver best results \cite{Tapprints, Accessory}.
  \item \textbf{Dataset}: In comparison to related studies, a dataset containing data points collected in a laboratory environment and the field environment will be acquired from a total of 27 users. This data will contain the index finder and thumb as input modalities and standing and sitting as body postures while input. 
  \item \textbf{Feature extraction}: \textit{TapPrints} shows a deliberate list of features \cite{Tapprints} that will be partially adopted. The features extracted will be discussed in section TODO.
  \item \textbf{Classification}: A feed-forward neural network, as well as a support vector machine with radial kernel will be used for classification. More will be covered in the classifcation section.
\end{itemize}

% It is plausible that the environment the user is currently in, has an effect on the recorded taps. If we imagine a user sitting in a moving vehicle, the motion sensor will include the vibrations of the motor. Therefore, this work will aim at collecting taps and corresponding motion sensor data from both a laboratory and a field environment to test how prediction accuracies compare to both environments. For this purpose, an iOS application with different tap area grids, as we have seen in \textit{ACCessory} and \textit{Touchlogger}, will be evaluated in the upcoming sections.