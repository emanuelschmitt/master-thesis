\chapter{Related Work\label{cha:chapter2}}
A tap location inference is a form of eavesdropping, this chapter will shed light into similar approaches of side-channel attacks that have been revealed by researchers in the past. The first section deals with different kinds of device emanations that enable attackers to obtain confidential information. The second section covers the foundations of this work as it discusses previous similar attempts to predict tap locations on smartphone screens.

\section{Eavesdropping on Emanations}

Eavesdropping is defined as the the practice of secretly listening to private conversations of others without their consent \cite{black1990black}. As this definition originally refers to conversations between humans, eavesdropping can also be seen in terms of human-computer-interaction. In this context, the computer is seen as one conversational partner whereas the user interacting with the device is seen as the other. The channel in which human-computer interaction takes place has various forms. Typically, a human may enter information on a peripheral device while the computer gives feedback through an image representation. However, as in recent times, conversations though natural language interfaces are also gaining popularity \cite{shneiderman2016designing}.

In order to spy on these conversations, various techniques have been revealed in the past of which a subset involves the utilization of leaking emanations. These emanations can be monitored in order to carefully reconstruct the contained information. As the emanations occur in various formats, a categorization has been made based on the sensory channel they transpire. Therefore, the following sections will cover eavesdropping techniques based on acoustic, optical, electromagnetic and motion emanations.

% Eavesdropping is secretly listening to the private conversation of others without their consent, as defined by Black's Law Dictionary.[1]
% two words in interaction and 
% Inferring user interactions through side channels has been of great interest to the academic world throughout history. As this thesis will cover a modern approach by recording sensory information provided by the Apple iPhone, an early and prominent example of spying on emanations reaches far back in time. \\

%   % not having to modify the host system.

% Ever since, various user interaction inference experiments have been conducted by researchers worldwide. However, in order to categorize these different approaches found in literature, we will divide these based on the emanation channel that was spied on. This categorization approach is more suitable since device model and user interaction strategies have frequently changed in time.\\ 

% The literature denoted that user inference can be perused with the help of acoustic, optical, electro-magnetic and on sensory emanation. We will describe these in the following sections.

\subsection{Acoustic Emanations}
One way of spying on electrical devices is by utilizing the acoustic channel \cite{Backes:2010:ASA:1929820.1929847,1301311,Zhuang:2009:KAE:1609956.1609959}. Many electronic devices deploy tiny mechanics that generate sounds as a byproduct during interactions or during operation. These distinct sounds can differ in their characteristics making them adequate to identify the original information currently being processed by the machine. In these scenarios a potential eavesdropper targets a microphone in near proximity of the target device to capture the audio signals the device is currently exposing. A learning algorithm is then applied to the audio signals to reconstruct information.

In 2010, \citeauthor{Backes:2010:ASA:1929820.1929847} examined the problem of acoustic emanations of dot matrix printers, which where, at that time, still commonly used in banks and medical offices. By using a simple consumer-grade microphone, the researchers were able to recover whole sentences the printer was processing \cite{Backes:2010:ASA:1929820.1929847}. By processing the audio samples and extracting features from the frequency domain, the researchers where able to train a hidden markov model to reconstruct individual characters based on the sound inputs. Consequently, in order to demonstrate a potential attack, the researchers deployed the system in a medical office being able to obtain up to 72\% of the sentences being printed on medical subscriptions \cite{Backes:2010:ASA:1929820.1929847}.

Being inspired by the findings regarding the dot matrix printer, \citeauthor{1301311} investigated acoustic emanations produced by hitting keystrokes on desktop and notebook keyboards. Following their hypothesis claiming that each keystroke has a macroscopic difference in it's construction mechanics, as well as a distinct reverberation caused by the position on the keyboard, individual keystrokes were recorded \cite{1301311}. Researchers then extracted features from the audio signals and passed them into a neural network. In an experiment performing 300 keystrokes, 79\% of the characters could be correctly recognized \cite{1301311}. As this technique required substantial training before recognition, other studies have reached similar accuracies using an unsupervised approach \cite{Zhuang:2009:KAE:1609956.1609959} and by using acoustic dictionaries \cite{Berger:2006:DAU:1180405.1180436}.

% Maybe some text to round things up...
\subsection{Optical Emanation}
Besides acoustic emanations, optical emanations can also pose a valuable source of information for a potential eavesdropper. Most electronic devices, such as notebook, smartphones and tablet computers, provide graphical user interfaces through their own built-in screens. Even though these screens are meant to target the human eye, they can reflect off other surfaces. The reflections can be caught by high resolution camera sensors, which can unintendedly reveal private information.

One example of the use of optical emanations has been developed by the researcher \citeauthor{1004358} aiming to eavesdrop on cathode-ray-tube(CRT) monitors at distance \cite{1004358}. The researcher has shown that the information displayed on the monitor can be reconstructed from it's distorted or even diffusely reflected light. In an experiment, \citeauthor{1004358} targeted a screen against a wall while the reflections of the screen were captured using a photomultiplier. The results showed that enough high-frequency content remained in the emitted light for a computer to reconstruct the original image \cite{1004358}. Moreover, a similar approach that comprises reflections has been shown by \citeauthor{4531151}, however, focusing on LCD displays. In this experiment, the researchers caught reflections in various objects that are commonly to be found in close proximity to a computer screen. Such objects included eyeglasses, tea pots, spoons and even plastic bottles. This work was later extended to additionally capture screens based on the reflections on the human eye's cornea \cite{5207653}.

\subsection{Electro-magnetic Emanation}
As electric currents flow through computer components, they emit electromagnetic waves to their near surrounding. These electromagnetic radiations can be picked up as a side channel using sensitive equipment in order to retrieve data. Electromagnetic emanations have been a research topic that has been present for several decades while the first research conducted reaches far back in time.

Back in 1943, a research group under the codename TEMPEST, a subdivision of the NSA\footnote{National Security Agency}, were able to infer information from the infamous Bell Telephone model 131-B2, a teletype terminal which was used for encrypting wartime communication \cite{tempest}. Using an oscilloscope, researchers could capture leaking electromagnetic signals from the device and by carefully examining the peaks of the recorded signals, the plain message the device was currently processing could be reconstructed \cite{tempest}. This technique was later advanced and used in the the Vietnam war where the US military could detect approaching Viet Cong trucks giving them an immense competitive advantage over their enemies \cite{nalty2005war}. Today, TEMPEST is a security standard for electronic devices ensuring that certified devices do not accidentally emanate confidential information \cite{niaTempest}.

A second prominent finding of eavesdropping on electromagnetic emanations was shown by \citeauthor{vanEck:1985:ERV:7307.7308} discovering that cathode-ray-tube monitors could be spied upon from a distance \cite{vanEck:1985:ERV:7307.7308}. By using general market equipment, such as antennas \citeauthor{vanEck:1985:ERV:7307.7308} and standard receivers, signals emitted from the monitor cable could be received. Since these cables only transmit the video signals for visualization, the researcher could display the visual output of the target monitor revealing a full screen cast of the original image. This attack is referred to in literature as \textit{Van Eck Phreaking} \cite{S&S,koch2012role}.

Moreover, research has shown that side-band electromagnetic emanations are present in keyboards \cite{Vuagnoux:2009:CEE:1855768.1855769}, computer screens \cite{vanEck:1985:ERV:7307.7308,kuhn2004electromagnetic}, printers \cite{przesmycki2014measurement}, computer interfaces, such as USB 2 \cite{nowosielski2014compromising} and the parallel port \cite{serialcablearticle} and in so-called Smart Cards \cite{Quisquater:2001:EAM:646803.705980}.

\subsection{Motion Emanation}
As mentioned in the introduction section, modern devices, such as tablets or smartphones, are increasingly equipped with highly responsive sensors enabling the devices to sense interactions with their environment. As touch screen interactions, such as typing the keyboard or tapping icons, require the user to apply a certain force while entering information, this motion can be captured by the sensors in order to be used as a side-channel attack \cite{Tapprints,Accessory,Touchlogger}.

\citeauthor{Marquardt:2011:IDV:2046707.2046771} conducted an experiment where an Apple iPhone capturing accelerometer motion was placed next to a desktop keyboard. Subjects then had to enter sentences while the application was monitoring the user's motion. The researchers could decode the accelerometer signals by mapping the vibration caused by the typing motion to individual keystrokes of the keyboard. The decoded characters were then matched based on a dictionary to obtain words the user was typing. As a result, words could successfully be obtained with an accuracy of up to 80\% \cite{Marquardt:2011:IDV:2046707.2046771}.

As motion emanations are highly relevant for this work, the next section will be dedicated to further work regarding this topic.

\section{Eavesdropping on touch screen user interactions}
As we have seen in the previous section, confidential information can be obtained utilizing emanations from various channels. However, with the rise in software keyboard usage, the same discussed methods that extract information from keyboards do not apply to tap interactions on a touchscreen surface. Since a touchscreen does not embody fine mechanics producing sounds nor does it have emanating cables, the research community has developed nouvelle methods to spy on these kind of user interactions.

The general idea behind the three approaches, that are going to be discuss in the following, is that a tap, or to be more precise the magnitude of the force of a tap, on a specific touch screen location creates an identifiable pattern on the motion sensors that can be sufficient to infer the initial tap location.

\subsubsection{Touchlogger}

The first paper regarding this security threat was published by \citeauthor{Touchlogger}. In their proof-of-concept study they created an Android application which displays a 10-digit PIN-pad. During interactions with the PIN-pad, the accelerometer signals were monitored and used for later data analysis. Having observed that a tap movement affects the rotation angle of the screen, the researchers handcrafted features based on the path of the \textit{pitch}\footnote{The pitch-angle corresponds to the x-axis of the accelerometer.} and the \textit{roll}\footnote{The roll angle corresponds to the y-axis of the accelerometer.} angles of the accelerometer. Both angles were intersected to find a dominating edge on where the tap had presumably taken place. By using a probability density function the researchers were able to achieve an average accuracy of 70\% for inferred PIN-pad digits.

Even though \textit{Touchlogger} was a promising first step, due to it's low granularity of only 10 distinguishable large screen areas, it remained unclear if the attack could be carried out on a full software keyboard. Furthermore, since the inference was performed on a single smartphone model, the question was left open whether other smartphones or tablet computers are similarly vulnerable.

\subsubsection{ACCessory}

In order to show the feasibility for a full software keyboard, \citeauthor{Accessory} performed a second attempt to the problem by creating \textit{ACCessory}. \textit{ACCessory} is an Android application with functionalities similar to the previously mentioned \textit{Touchlogger}, however, differing in the granularity of distinguishable areas to tap. In an experiment, the researchers tested tap location inference in two separate modes. The first one, the \textit{area mode}, consisted of a 60-cell tapping grid and the second one, the \textit{character mode}, consisted of a standard QWERTY keyboard. 

As a result, on the 60-cell grid in \textit{area mode}, individual regions could be inferred with an accuracy up to 24\% using a Random Forest classifier. The corresponding data set consisted of 1300 keystrokes from 4 distinct users. 
For the \textit{character mode}, three subjects in total had to enter pangram passwords on the QWERTY keyboard. By combining the individual keystrokes into a sequence and assuming recognition errors in individual characters, the researchers could create a ranked list of candidate passwords by running a maximum likelihood search for the most probable classification errors. Here, 6 out of 99 password could be inferred under 4.5 median trials given that one trails refers to traversing down one item of the candidate list. Furthermore, the majority of 59 out of 99 passwords could be inferred within $2^{15}$ median trials.

As general result, even though the overall accuracies of the learning system scored rather low, the researchers could significantly reduce the search space for reconstructing a password.

\subsubsection{TapPrints}

The most comprehensive study to date regarding motion sensor emanations was conducted by \citeauthor{Tapprints} and differs from \textit{ACCessory} and \textit{Touchlogger} in many important ways. While the previous studies are both evaluated on Android smartphones, \textit{TapPrints} investigates the tap inference on both iOS and Android platforms including tablets and smartphones alike. 

Another important point of differentiation is the overall learning system. In order to raise the level of entropy, \textit{TapPrints} combines readings from the accelerometer and gyroscope. For feature extraction, time-domain and frequency-domain features, as well as the correlation and angles between individual sensor components are considered. The researchers then used an ensemble method for classification purposes combining decision tress, support vector machines, k-nearest neighbors and multinomial logistic regression in a winner-takes-it-all\footnote{This implies that all classifiers classify separately and the classifier with the highest prediction score wins.} voting fashion. The data set collected in this study contains over 40.000 individual taps collected from 10 different users. In addition, the researchers also requested user to use different input modalities while typing including the usage of the index finger and the thumb.

The \textit{TapPrints} paper contains two experiments: The first is an icon tapping experiment where icons are arranged in a 20 cell grid. The second one is a letter tapping experiment involving the standard software keyboard offered by the operating system. In the icon tapping experiment, an average accuracy of 78\% was achieved for the iPhone whereas 67\% of icon taps could be correctly inferred on the Android device. The researchers could also show that taps could also be inferred from users that were not part of the training process.

In the letter tapping experiment users were asked to enter pangram\footnote{A pangram is a sentence using every letter of a given alphabet at least once.} sentences on the OS soft-keyboard. Results showed that on both iPhone and Android an average of 43\% of the letters could be correctly classified. Even though the average accuracy for individual letters were not particularly high, \citeauthor{Tapprints} could show that when pangrams were repeatedly entered, a majority vote could be applies to individual character recognitions allowing to recover the whole pangram in approximately 15 trials. 

To sum up, \textit{TapPrints} could demonstrate that motion sensor do indeed pose a latent security threat. As of the high accuracies on the 20-cell grid, the researchers could show that PINs could be obtained across unseen users and devices. Furthermore, it was also reveled that due to a majority voting scheme repeatedly entered phrases, such as passwords, could also be obtained in a malicious attack.

\subsubsection{Comparison to similar studies}

Since the data used in \textit{TapPrints} and in the other mentioned studies was collected in a controlled environment \cite{Accessory,Touchlogger,Tapprints}, it is not possible to tell if the feasibility of tap inference will also apply to data collected in a field environment. As this has not been investigated, this will form one of the central research questions in this work.

To draw the border between this study and the previous mentioned ones, this study will differ or relate as follows:
% TODO: build reference to individual chapters
\begin{itemize}
  \item \textbf{User interface}: For data acquisition, the user interface will cover tap area grids, as we have seen in \textit{ACCessory}, \textit{Touchlogger} and \textit{TapPrints}, with 4, 12 and 20 distinguishable classes.
  \item \textbf{Devices}: Unlike \textit{Touchlogger} and \textit{ACCessory} and due to simplicity, the devices used in this study will be on the iOS platform. Apple iPhone 6, 6s and 7 will be considered.
  \item \textbf{Motion sensors}: \textit{TapPrints} has shown that the gyroscope yields more information than the accelerometer \cite{Tapprints}, therefore both sensors will be monitored. Furthermore, sensors will be read at a frequency of 100Hz, since this had been proven to deliver best results \cite{Tapprints, Accessory}.
  \item \textbf{Data set}: In comparison to related studies, a data set containing data points collected in a laboratory environment and the field environment will be acquired. This data will contain the index finder and thumb as input modalities and standing and sitting as possible body postures.
  \item \textbf{Feature extraction}: \textit{TapPrints} shows a deliberate list of features \cite{Tapprints} that will be partially adopted.
  \item \textbf{Classification}: A feed-forward neural network, as well as a support vector machine with RBF-kernel will be used for classification.
\end{itemize}

% It is plausible that the environment the user is currently in, has an effect on the recorded taps. If we imagine a user sitting in a moving vehicle, the motion sensor will include the vibrations of the motor. Therefore, this work will aim at collecting taps and corresponding motion sensor data from both a laboratory and a field environment to test how prediction accuracies compare to both environments. For this purpose, an iOS application with different tap area grids, as we have seen in \textit{ACCessory} and \textit{Touchlogger}, will be evaluated in the upcoming sections.